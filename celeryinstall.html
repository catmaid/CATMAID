

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Installation of the CELERY task queue &mdash; CATMAID 2015.7.17-dev documentation</title>
    
    <link rel="stylesheet" href="_static/jinja.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/style.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '2015.7.17-dev',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="CATMAID 2015.7.17-dev documentation" href="index.html" />
    <link rel="up" title="Developer Documentation" href="developer.html" />
    <link rel="next" title="Creating a CATMAID instance on EC2" href="ami.html" />
    <link rel="prev" title="Django unit tests for CATMAID" href="djangounittest.html" /> 
  </head>
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="ami.html" title="Creating a CATMAID instance on EC2"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="djangounittest.html" title="Django unit tests for CATMAID"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">CATMAID 2015.7.17-dev documentation</a> &raquo;</li>
          <li class="nav-item nav-item-1"><a href="developer.html" accesskey="U">Developer Documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="installation-of-the-celery-task-queue">
<h1>Installation of the CELERY task queue<a class="headerlink" href="#installation-of-the-celery-task-queue" title="Permalink to this headline">¶</a></h1>
<p>Some tasks of CATMAID (e.g. cropping) are done in the background.
These are managed by the task queue Celery. The job of telling
Celery about a new task to process is done by a message broker &#8211;
different brokers are supported by Celery. By default a simple
Python module is utilized that uses the Django data base to store
messaging information. Alternatively, one may use message brokers
like RabbitMQ, which can be configured in the <code class="docutils literal"><span class="pre">settings.py</span></code> file.</p>
<p>In case Celery is not running it is no problem for Django/CATMAID.
As long as the message broker is around, CATMAID will accept tasks
(e.g a cropping job). They will get executed when Celery is running
again.</p>
<p>This first section guides you through the setup of Celery and the
simplest message broker provided by Kombu, it used Django&#8217;s database
to store messages. Afterwards, an alternative broker, RabbitMQ, is
described.</p>
<div class="section" id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h2>
<p>The setup of Django needs to be completed before configuring Celery.</p>
</div>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>The configuration of celery and the message broker happens in the
<code class="docutils literal"><span class="pre">settings.py</span></code> file. The example file contains a configuration that
should be ready to go. A quick run through the relevant settings
follows.</p>
<p>To be able to use Celery, it needs to be imported and initialized
first. This is done by this lines:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">djcelery</span>
<span class="n">djcelery</span><span class="o">.</span><span class="n">setup_loader</span><span class="p">()</span>
</pre></div>
</div>
<p>To specify how many concurrent tasks Celery should execute, you can
use the following variable:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">CELERYD_CONCURRENCY</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>By default this is the number of CPUs available and the above line
sets it to one.</p>
<p>Then Celery and Django need some information about the message broker
in use. Since we here refer to kombu, the following settings
are important to get this specific broker to work:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">INSTALLED_APPS</span> <span class="o">+=</span> <span class="p">(</span><span class="s">&quot;kombu.transport.django&quot;</span><span class="p">,)</span>
<span class="n">BROKER_URL</span> <span class="o">=</span> <span class="s">&#39;django://&#39;</span>
</pre></div>
</div>
<p>This will make kombu use the Django database for its messages. Although,
this is fine for a small and simple setup, it is recommended to use a
different message broker for larger setups. There is more information on
the limitations of and alternatives to this approach in
<a class="reference external" href="http://docs.celeryproject.org/en/latest/getting-started/brokers/django.html">Celery&#8217;s documentation</a>.</p>
<p>To initialize Celery, call the syncdb sub-command of your <code class="docutils literal"><span class="pre">manage.py</span></code>
(from within the virtualenv):</p>
<div class="highlight-python"><div class="highlight"><pre>python manage.py syncdb
</pre></div>
</div>
<p>This will create some tables for Celery and django-kumbo in the Django
data base. You should then be able to run the Celery daemon (also from
within the virtualenv):</p>
<div class="highlight-python"><div class="highlight"><pre>python manage.py celeryd -l info
</pre></div>
</div>
<p>The Celery daemon should be integrated in your system to be started
automatically. There are is a <code class="docutils literal"><span class="pre">init</span></code> script available in the Celery code
base that could be used here. Also, make sure that this Celery daemon
process has the permissions to write to the temporary directory
(<code class="docutils literal"><span class="pre">TMP_DIR</span></code>).</p>
</div>
<div class="section" id="message-brokers">
<h2>Message Brokers<a class="headerlink" href="#message-brokers" title="Permalink to this headline">¶</a></h2>
<p>It is the so called message broker who takes tasks and tells Celery to execute
them. There are several ones around and the section uses RabbitMQ as an
alternative to the simple Django based one used above. RabbitMQ is very fast
and reliable and can be configured to be manageable through Django&#8217;s admin
interface.</p>
<p>First, the RabbitMQ server has to be installed:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo apt-get install rabbitmq-server
</pre></div>
</div>
<p>This should start it automatically. RabbitMQ comes with a plugin infrastructure
and one particular useful plugin is one that adds support for management
commands. Based on this one is able to get information on Celery workers through
the broker from within Django&#8217;s admin interface. To enable it, call:</p>
<blockquote>
<div>sudo /usr/lib/rabbitmq/lib/rabbitmq-server-3.2.3/sbin/rabbitmq-plugins enable rabbitmq_management</div></blockquote>
<p>After enabling or disabling plugins, RabbitMQ has to be restarted:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo service rabbitmq-server restart
</pre></div>
</div>
<p>To display a list of all available plugin and whether they are enabled, call:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo /usr/lib/rabbitmq/lib/rabbitmq-server-3.2.3/sbin/rabbitmq-plugins list
</pre></div>
</div>
<p>This also enables a web-interface will be available on port 15672. The default
user and password combination is guest/guest.</p>
<p>To collect worker events, one has to start <code class="docutils literal"><span class="pre">celeryd</span></code> with the <code class="docutils literal"><span class="pre">-E</span></code> argument,
e.g.:</p>
<div class="highlight-python"><div class="highlight"><pre>python manage.py celeryd -l info -E
</pre></div>
</div>
<p>And to retrieve event snapshots from all workers, start <code class="docutils literal"><span class="pre">celerycam</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre>python manage.py celerycam
</pre></div>
</div>
<p>All tasks will then be manageable from with Django&#8217;s admin interface.</p>
</div>
<div class="section" id="periodic-tasks">
<span id="sec-celery-periodic-tasks"></span><h2>Periodic Tasks<a class="headerlink" href="#periodic-tasks" title="Permalink to this headline">¶</a></h2>
<p>The Celery infrastructure can also be used to execute tasks periodically.
For example, it might be wanted that the clean-up of cropped stacks
should take place every night. This can be realized without changing any
source code, but add very little Python code to two files. First the
<code class="docutils literal"><span class="pre">settings.py</span></code> file needs to be extended to let Celery workers import a
tasks file:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># Disable automatic clean-up of the cropping tool</span>
<span class="n">CROP_AUTO_CLEAN</span> <span class="o">=</span> <span class="bp">False</span>
<span class="c"># Let Celery workers import our tasks module</span>
<span class="n">CELERY_IMPORTS</span> <span class="o">=</span> <span class="p">(</span><span class="s">&quot;tasks&quot;</span><span class="p">,</span> <span class="p">)</span>
</pre></div>
</div>
<p>The code above also disables the automatic cleaning which is done on
every download request for a cropped stack.</p>
<p>Next we need to create a new file <code class="docutils literal"><span class="pre">tasks.py</span></code> in the folder where the
<code class="docutils literal"><span class="pre">settings.py</span></code> file resides. The name &#8220;tasks&#8221; is used by convention, but
is in fact arbitrary. If it is changed the <code class="docutils literal"><span class="pre">CELERY_IMPORTS</span></code> variable
needs to be adjusted, too. This file contains the task definitions:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">celery.schedules</span> <span class="kn">import</span> <span class="n">crontab</span>
<span class="kn">from</span> <span class="nn">celery.task</span> <span class="kn">import</span> <span class="n">periodic_task</span>

<span class="c"># Define a periodic task that runs every day at midnight and noon.</span>
<span class="c"># It removes all cropped stacks that are older than 12 hours.</span>
<span class="kn">from</span> <span class="nn">catmaid.control.cropping</span> <span class="kn">import</span> <span class="n">cleanup</span> <span class="k">as</span> <span class="n">cropping_cleanup</span>
<span class="nd">@periodic_task</span><span class="p">(</span> <span class="n">run_every</span><span class="o">=</span><span class="n">crontab</span><span class="p">(</span> <span class="n">hour</span><span class="o">=</span><span class="s">&quot;0,12&quot;</span> <span class="p">)</span> <span class="p">)</span>
<span class="k">def</span> <span class="nf">cleanup_cropped_stacks</span><span class="p">():</span>
    <span class="n">twelve_hours</span> <span class="o">=</span> <span class="mi">43200</span> <span class="c"># seconds</span>
    <span class="n">cropping_cleanup</span><span class="p">(</span> <span class="n">twelve_hours</span> <span class="p">)</span>
    <span class="k">return</span> <span class="s">&quot;Cleaned cropped stacks directory&quot;</span>
</pre></div>
</div>
<p>One can also use the <code class="docutils literal"><span class="pre">datetime.timedelta</span></code> function to specify when and
how often the task should be run.</p>
<p>Despite defining such a task, the Celery process needs to be run in
so-called &#8220;beat&#8221; mode:</p>
<div class="highlight-python"><div class="highlight"><pre>python manage.py celeryd -B -l info
</pre></div>
</div>
<p>This mode requires that <code class="docutils literal"><span class="pre">celeryd</span></code> can write to the project directory.
By default it will create there a file called <code class="docutils literal"><span class="pre">celerybeat-schedule</span></code>.
To adjust this file name and path, have a look in the Celery manual.
Again, an <code class="docutils literal"><span class="pre">init</span></code> script for automatic starting is available in the
Celery code base.</p>
</div>
<div class="section" id="celery-daemon">
<h2>Celery Daemon<a class="headerlink" href="#celery-daemon" title="Permalink to this headline">¶</a></h2>
<p>It is not very convenient to have Celery run manually all the time. After
all, a server reboot wouldn&#8217;t bring it up again. Therefore it is desirable
to have Celery run as an automatically started as a <em>daemon</em>.</p>
<p>If you don&#8217;t care whether Celery is automatically stated after booting, you
can run it as a daemon also from your terminal as well. Make sure you have
a folder ready where the user running Celery has permissions to write.
Here we assume that there is a folder <code class="docutils literal"><span class="pre">run</span></code> in which log and pid files
are created:</p>
<div class="highlight-python"><div class="highlight"><pre>python manage.py celeryd --logfile run/celeryd.log --pidfile run/celeryd.pid -l info
</pre></div>
</div>
<p>Or when using <code class="docutils literal"><span class="pre">celerybeat</span></code> as well:</p>
<div class="highlight-python"><div class="highlight"><pre>python manage.py celeryd --logfile run/celeryd.log --pidfile run/celeryd.pid -B -l info
</pre></div>
</div>
<p>Now this could be run in a Screen session and you can safely disconnect from
the server. However, like said before, this won&#8217;t survive a server reboot.</p>
<p>Depending on your operating system manages the boot process, you can use
the <code class="docutils literal"><span class="pre">init</span></code> scripts provided in the Celery source. A detailed description
can be found in the
<a class="reference external" href="http://ask.github.com/celery/cookbook/daemonizing.html">Celery documentation</a>.
In short, you need to to do the following: First, get the following file:</p>
<div class="highlight-python"><div class="highlight"><pre>https://github.com/ask/celery/blob/master/contrib/generic-init.d/celeryd
</pre></div>
</div>
<p>Copy it to the folder <code class="docutils literal"><span class="pre">/etc/init.d/</span></code> and mark it executable. Then you need
to create a default configuration file <code class="docutils literal"><span class="pre">/etc/default/celeryd</span></code> (taken from
the Celery documentation):</p>
<div class="highlight-python"><div class="highlight"><pre># Name of nodes to start, here we have a single node
CELERYD_NODES=&quot;w1&quot;
# or we could have three nodes:
#CELERYD_NODES=&quot;w1 w2 w3&quot;

# Where to chdir at start. (CATMAID Django project dir.)
CELERYD_CHDIR=&quot;/path/to/CATMAID/django/projects/mysite/&quot;

# Python interpreter from environment. (in CATMAID Django dir)
ENV_PYTHON=&quot;/path/to/CATMAID/django/env/bin/python&quot;

# How to call &quot;manage.py celeryd_multi&quot;
CELERYD_MULTI=&quot;$ENV_PYTHON $CELERYD_CHDIR/manage.py celeryd_multi&quot;

# How to call &quot;manage.py celeryctl&quot;
CELERYCTL=&quot;$ENV_PYTHON $CELERYD_CHDIR/manage.py celeryctl&quot;

# Extra arguments to celeryd
CELERYD_OPTS=&quot;--time-limit=300 --concurrency=1&quot;

# Name of the celery config module.
CELERY_CONFIG_MODULE=&quot;celeryconfig&quot;

# %n will be replaced with the nodename.
CELERYD_LOG_FILE=&quot;/var/log/celery/%n.log&quot;
CELERYD_PID_FILE=&quot;/var/run/celery/%n.pid&quot;

# Workers should run as an unprivileged user.
CELERYD_USER=&quot;celery&quot;
CELERYD_GROUP=&quot;celery&quot;

# Name of the projects settings module.
export DJANGO_SETTINGS_MODULE=&quot;settings&quot;
</pre></div>
</div>
<p>Please adjust the <code class="docutils literal"><span class="pre">CELERY_CHDIR</span></code> variable and the <code class="docutils literal"><span class="pre">--concurrency</span></code>
parameters to your situation. Also, this configuration expects that an
unprivileged user and group with the name <code class="docutils literal"><span class="pre">celery</span></code> has been created.
If this hasn&#8217;t been done already, you can do this as follows:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo adduser --system --no-create-home --disabled-login --disabled-password --group celery
</pre></div>
</div>
<p>Finally, you have to tell the system about the new <code class="docutils literal"><span class="pre">init</span></code> script:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo update-rc.d celeryd defaults
</pre></div>
</div>
<p>Now you (and the system while booting up) should be able to start
celery:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo service celeryd start
</pre></div>
</div>
<p>Note, that the <code class="docutils literal"><span class="pre">celery</span></code> user needs to have read and write access
to the temporary directory of CATMAID. E.g the cropping tool will
save its cropped sub-stacks there.</p>
<p>If you want to have periodic tasks managed by a <code class="docutils literal"><span class="pre">celerybeat</span></code>
daemon, some steps are yet to be done. First, you need to get another
<code class="docutils literal"><span class="pre">init</span></code> script. The Celery repository provides one as well:</p>
<div class="highlight-python"><div class="highlight"><pre>https://github.com/ask/celery/blob/master/contrib/generic-init.d/celerybeat
</pre></div>
</div>
<p>Again, this needs to be moved to the folder <code class="docutils literal"><span class="pre">/etc/init.d/</span></code> and
marked executable. Finally, tell the operating system about it:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo update-rc.d celerybeat defaults
</pre></div>
</div>
<p>Next, append the following lines to your Celery configuration file
<code class="docutils literal"><span class="pre">/etc/default/celeryd</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># Where to chdir at start.</span>
<span class="n">CELERYBEAT_CHDIR</span><span class="o">=</span><span class="s">&quot;$CELERYD_CHDIR&quot;</span>

<span class="c"># Path to celerybeat</span>
<span class="n">CELERYBEAT</span><span class="o">=</span><span class="s">&quot;$ENV_PYTHON $CELERYD_CHDIR/manage.py celerybeat&quot;</span>

<span class="c"># Extra arguments to celerybeat</span>
<span class="n">CELERYBEAT_OPTS</span><span class="o">=</span><span class="s">&quot;--schedule=/var/run/celerybeat-schedule&quot;</span>

<span class="n">CELERYBEAT_LOG_FILE</span><span class="o">=</span><span class="s">&quot;/var/log/celery/celerybeat.log&quot;</span>
<span class="n">CELERYBEAT_PID_FILE</span><span class="o">=</span><span class="s">&quot;/var/run/celery/celerybeat.pid&quot;</span>

<span class="c"># Celery beat should run as an unprivileged user</span>
<span class="n">CELERYBEAT_USER</span><span class="o">=</span><span class="s">&quot;celery&quot;</span>
<span class="n">CELERYBEAT_GROUP</span><span class="o">=</span><span class="s">&quot;celery&quot;</span>
</pre></div>
</div>
<p>A &#8220;beating&#8221; Celery can now be started additionally:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo service celerybeat start
</pre></div>
</div>
<p>With these settings periodic tasks get executed after a reboot
as well.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><p class="logo"><a href="index.html">
  <img class="logo" src="_static/catmaidlogo.png" alt="Logo" align="left"/>
</a></p>
<br clear="all"/><br /><h3><a href="index.html">Home</a></h3>
<h3><a href="screenshots.html">Screenshots</a></h3>
<h3><a href="whouses.html">Who uses it?</a></h3>
<h3><a href="publications.html">Publications</a></h3>
<h3><a href="funding.html">Funding</a></h3>
<h3><a href="credits.html">Credits</a></h3>
<h3>Useful Links</h3>
<ul>
  <li><a href="http://github.com/catmaid/CATMAID">Source Code</a></li>
  <li><a href="http://github.com/catmaid/CATMAID/issues">Issues</a></li>
  <li><a href="http://groups.google.com/group/CATMAID">Mailinglist</a></li>
  <li><a href="http://fly.mpi-cbg.de/~saalfeld/catmaid/">Old page</a></li>
</ul>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-17713054-5']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Installation of the CELERY task queue</a><ul>
<li><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li><a class="reference internal" href="#installation">Installation</a></li>
<li><a class="reference internal" href="#message-brokers">Message Brokers</a></li>
<li><a class="reference internal" href="#periodic-tasks">Periodic Tasks</a></li>
<li><a class="reference internal" href="#celery-daemon">Celery Daemon</a></li>
</ul>
</li>
</ul>
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation</a><ul>
  <li><a href="developer.html">Developer Documentation</a><ul>
      <li>Previous: <a href="djangounittest.html" title="previous chapter">Django unit tests for CATMAID</a></li>
      <li>Next: <a href="ami.html" title="next chapter">Creating a CATMAID instance on EC2</a></li>
  </ul></li>
  </ul></li>
</ul>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy; Copyright 2015, CATMAID Developers.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a>.
    </div>
  </body>
</html>